version: '3.8'

services:

  zookeeper:
    image: bitnami/zookeeper:${ZOOKEEPER_VERSION:-3.8}
    hostname: zookeeper
    container_name: zookeeper
    healthcheck:
      test: ["CMD", "zkServer.sh", "status"]
      interval: 5s
      retries: 5
      timeout: 5s
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
    volumes:
      - zookeeper_data:/bitnami/zookeeper
    ports:
      - "2181:2181"
    networks:
      - kafka-net

  # --- Three Kafka brokers with SASL/SCRAM and ACLs ---
  kafka1:
    image: bitnami/kafka:${KAFKA_VERSION:-3.5.1}
    hostname: kafka1
    container_name: kafka1
    depends_on:
      - zookeeper
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,SASL_PLAINTEXT://0.0.0.0:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:9092,SASL_PLAINTEXT://kafka1:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_SASL_ENABLED_MECHANISMS=SCRAM-SHA-256
      - KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL=SCRAM-SHA-256
      - KAFKA_CFG_AUTHORIZER_CLASS_NAME=kafka.security.authorizer.AclAuthorizer
      - KAFKA_CFG_ALLOW_EVERYONE_IF_NO_ACL_FOUND=true
      - KAFKA_CFG_SUPER_USERS=User:admin
      # Define SCRAM users
      - KAFKA_CLIENT_USERS=admin,client
      - KAFKA_CLIENT_PASSWORDS=adminpwd,client-secret
      - KAFKA_CFG_NUM_PARTITIONS=3
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=3
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
    volumes:
      - kafka1_data:/bitnami/kafka
      - ./config/client.properties:/opt/bitnami/kafka/config/client.properties
    ports:
      - "9092:9092"
      - "9093:9093"
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 5s
      timeout: 5s
      retries: 12
      start_period: 10s
    networks:
      - kafka-net

  kafka2:
    image: bitnami/kafka:${KAFKA_VERSION:-3.5.1}
    hostname: kafka2
    container_name: kafka2
    depends_on:
      - zookeeper
      - kafka1
    environment:
      - KAFKA_BROKER_ID=2
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,SASL_PLAINTEXT://0.0.0.0:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka2:9092,SASL_PLAINTEXT://kafka2:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_SASL_ENABLED_MECHANISMS=SCRAM-SHA-256
      - KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL=SCRAM-SHA-256
      - KAFKA_CFG_AUTHORIZER_CLASS_NAME=kafka.security.authorizer.AclAuthorizer
      - KAFKA_CFG_ALLOW_EVERYONE_IF_NO_ACL_FOUND=true
      - KAFKA_CFG_SUPER_USERS=User:admin
      # Define SCRAM users
      - KAFKA_CLIENT_USERS=admin,client
      - KAFKA_CLIENT_PASSWORDS=adminpwd,client-secret
      - KAFKA_CFG_NUM_PARTITIONS=3
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=3
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
    volumes:
      - kafka2_data:/bitnami/kafka
      - ./config/client.properties:/opt/bitnami/kafka/config/client.properties
    ports:
      - "9094:9092"
      - "9095:9093"
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 5s
      timeout: 5s
      retries: 12
      start_period: 15s
    networks:
      - kafka-net

  kafka3:
    image: bitnami/kafka:${KAFKA_VERSION:-3.5.1}
    hostname: kafka3
    container_name: kafka3
    depends_on:
      - zookeeper
      - kafka1
      - kafka2
    environment:
      - KAFKA_BROKER_ID=3
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092,SASL_PLAINTEXT://0.0.0.0:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka3:9092,SASL_PLAINTEXT://kafka3:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_SASL_ENABLED_MECHANISMS=SCRAM-SHA-256
      - KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL=SCRAM-SHA-256
      - KAFKA_CFG_AUTHORIZER_CLASS_NAME=kafka.security.authorizer.AclAuthorizer
      - KAFKA_CFG_ALLOW_EVERYONE_IF_NO_ACL_FOUND=true
      - KAFKA_CFG_SUPER_USERS=User:admin
      # Define SCRAM users
      - KAFKA_CLIENT_USERS=admin,client
      - KAFKA_CLIENT_PASSWORDS=adminpwd,client-secret
      - KAFKA_CFG_NUM_PARTITIONS=3
      - KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=3
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
    volumes:
      - kafka3_data:/bitnami/kafka
      - ./config/client.properties:/opt/bitnami/kafka/config/client.properties
    ports:
      - "9096:9092"
      - "9097:9093"
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 5s
      timeout: 5s
      retries: 12
      start_period: 20s
    networks:
      - kafka-net

  # --- ACL initialization ---
  kafka-init:
    image: bitnami/kafka:${KAFKA_VERSION:-3.5.1}
    container_name: kafka-init
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    volumes:
      - ./scripts:/scripts
      - ./config/client.properties:/opt/bitnami/kafka/config/client.properties
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka1:9093
    command: ["bash", "-c", "sleep 10 && /scripts/init-acls.sh"]
    restart: on-failure
    networks:
      - kafka-net

  # --- Logstash reading from Kafka ---
  logstash:
    image: docker.elastic.co/logstash/logstash:8.6.0
    container_name: logstash
    depends_on: 
      - kafka1
      - kafka2
      - kafka3
    volumes:
      - ./config/logstash/pipeline.conf:/usr/share/logstash/pipeline/logstash.conf:ro
    ports:
      - "5044:5044"
    networks:
      - kafka-net

  # --- AKHQ UI ---
  akhq:
    image: tchiotludo/akhq:latest
    container_name: akhq
    depends_on: 
      - kafka1
      - kafka2
      - kafka3
    ports:
      - "8080:8080"
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka1:9093"
                security.protocol: SASL_PLAINTEXT
                sasl.mechanism: SCRAM-SHA-256
                sasl.jaas.config: org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="adminpwd";
    networks:
      - kafka-net

  # --- Python producer ---
  producer:
      image: python:3.9-slim
      container_name: kafka-producer
      depends_on:
        kafka1:
          condition: service_healthy
        kafka2:
          condition: service_healthy
        kafka3:
          condition: service_healthy
      restart: unless-stopped
      volumes:
        - ./producer:/app:ro
      working_dir: /app
      environment:
        BOOTSTRAP_SERVERS: kafka1:9093,kafka2:9093,kafka3:9093
        TOPIC: ${KAFKA_TOPIC:-my-topic}
        SASL_USERNAME: client
        SASL_PASSWORD: client-secret
      entrypoint: >
        bash -c "
          echo 'â± Waiting for Kafka to be availableâ€¦' &&
          # Wait for Kafka to be ready
          sleep 30 &&
          echo 'âœ… Kafka is up, installing dependenciesâ€¦' &&
          pip install --no-cache-dir kafka-python &&
          echo 'ğŸš€ Starting producerâ€¦' &&
          python producer.py"
      networks:
        - kafka-net
      
  # --- Python consumer ---
  consumer:
    image: python:3.9-slim
    container_name: kafka-consumer
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ./consumer:/app:ro
    working_dir: /app
    environment:
      BOOTSTRAP_SERVERS: kafka1:9093,kafka2:9093,kafka3:9093
      TOPIC: ${KAFKA_TOPIC:-my-topic}
      GROUP_ID: ${CONSUMER_GROUP:-my-group}
      SASL_USERNAME: client
      SASL_PASSWORD: client-secret
    entrypoint: >
      bash -c "
        echo 'â± Waiting for Kafka to be availableâ€¦' &&
        # Wait for Kafka to be ready
        sleep 30 &&
        echo 'âœ… Kafka is up, installing dependenciesâ€¦' &&
        pip install --no-cache-dir kafka-python &&
        echo 'ğŸš€ Starting consumerâ€¦' &&
        python consumer.py
      "
    networks:
      - kafka-net

volumes:
  zookeeper_data:
  kafka1_data:
  kafka2_data:
  kafka3_data:

networks:
  kafka-net:
    driver: bridge